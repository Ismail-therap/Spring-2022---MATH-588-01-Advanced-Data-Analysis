---
title: "MATH 588"
subtitle: "HW1"
author: "Md Ismail Hossain"
date: "1/27/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE)
```

\newpage

# 1(a)

\textbf{Null Hypothesis:} Mean weights are same in group 0 and 1. \newline
\textbf{Alternative Hypothesis:} Mean weights are not same in group 0 and 1.
\
```{r}
library(readr)
fullBumpus <- read_table2("E:/NMT MS/Spring 22/MATH 588/Home_Work/Spring-2022---MATH-588-01-Advanced-Data-Analysis/HW1/HW1 files/fullBumpus.txt")


ttst1 = t.test(Weight~Survive,var.equal=TRUE,data = fullBumpus)
ttst1
```


\textbf{Comments:} According to the p-value [considering variance are same in both group] ($0.0101$) it can be said that there is statistically significant difference between two group (0 and 1) in terms of weights, at level of significance is $0.05$. 


\

```{r}
ttst2 = t.test(Weight~Survive,var.equal=FALSE,data = fullBumpus)
ttst2
```

\textbf{Comments:} According to the p-value [considering variance are not equal in both group] ($0.01141$) it can be said that there is statistically significant difference between two group (0 and 1) in terms of weights, at level of significance is $0.05$. 

\
So, in both case (variance same or different), the null hypothesis is rejected.

\pagebreak

# 1(b)

After observing the normal qqplot of the residual we can interpret that the data does not follow normal distribution. Because the lower tail and upper part in the plot not goes close to the straight line. We should take some sort of transformation before carry out the t-test. The data distribution seems right skewed, so log-transformation could leads the data to normal shape and we know normality is the key assumption for t-test.
\

```{r,results='hide',fig.show='hide'}
res = resid(lm(Weight~Survive, data = fullBumpus))
qqnorm(res)
qqline(res)
```

# 1(c)

```{r}
boxplot(Weight~Survive,data=fullBumpus)

# Showing IQR
aggregate(Weight~Survive,fullBumpus,IQR)
```

As we know if the IQRs is between 0.5 and 2.0, there is no cause for concern about unequal variances. But in our case we observed that the IQR is greater than 2 for the surviving sparrow (1). So, the variability seems different between this two groups for the weight.

\

# 1(d)

```{r}


HW1FakeCor <- read_table2("E:/NMT MS/Spring 22/MATH 588/Home_Work/Spring-2022---MATH-588-01-Advanced-Data-Analysis/HW1/HW1 files/HW1FakeCor.txt")


{par(mfrow=c(2,1))
boxplot(WeightA~Nest,data=HW1FakeCor)
boxplot(WeightB~Nest,data=HW1FakeCor)}
```

From the boxplot we have seen that Nest 4 and 9 have close mean values and similar types of weight distribution. So, birds in nest 4 and 9 are similar in weights and have correlated errors.


# 2(a)

```{r}
fullBumpus <- read_table2("E:/NMT MS/Spring 22/MATH 588/Home_Work/Spring-2022---MATH-588-01-Advanced-Data-Analysis/HW1/HW1 files/fullBumpus.txt")


mdl <- lm(Alar~Female+Weight,data = fullBumpus)
summary(mdl)
```


# 2(b)

```{r}
b0M = coef(mdl)[1]
b0M
b0F = coef(mdl)[1] + coef(mdl)[2]
b0F
b1 = coef(mdl)[3]
b1

```


# 2(c)

```{r}
fullBumpus$Female <- as.factor(fullBumpus$Female)
#with(fullBumpus, table(Female, as.numeric(Female)))
{plot(Alar~Weight, pch=as.numeric(Female),col=as.numeric(Female), main="Bumpus",data=fullBumpus) 
abline(b0M, b1, col=1, lty=1) 
abline(b0F, b1, col=2, lty=2)
legend(28, 240, c("Male", "Female"), col=1:2, lty=1:2, pch=1:2)}
```


Without the interaction between Female and weights, the fitted lines are parallel. Let's explore residual vs X plot

```{r}
{plot(resid(mdl)~fullBumpus$Weight, col=as.numeric(fullBumpus$Female),
pch=as.numeric(fullBumpus$Female))
abline(h=0)}
```

# 2(d)

```{r}
```


```{r}
mdlI = lm(Alar~Female*Weight, data=fullBumpus)
summary(mdlI)
b0M = coef(mdlI)[1]
b0F = coef(mdlI)[1] + coef(mdlI)[2]
b1M = coef(mdlI)[3]
b1F = coef(mdlI)[3] + coef(mdlI)[4]
{with(fullBumpus, plot(Alar~Weight, pch=as.numeric(Female),
col=as.numeric(Female), main="Bumpus"))
abline(b0M, b1M, col=1, lty=1)
abline(b0F, b1F, col=2, lty=2)
legend(28, 240, c("Male", "Female"), col=1:2, lty=1:2, pch=1:2)}
```




# 2(e)

```{r}
anova(mdl,mdlI)

```

The p-value for the F-statistic is greater than 0.05. So, at 5\% level of significance we conclude that the non-parallel slops are not significant or the interaction term is insignificant. So, we don't have good evidance of non-aparallel slopes.


# 2(f)

```{r}
confint(mdlI) 
```

The 95% CI for the difference of slopes (female-male)=[$-0.4166585$ ,$1.527374$] because interaction term representing difference between male and feamale.


# 3(a) (1)

```{r}
#install.packages("Sleuth3")
library(Sleuth3)
boxplot(PollenRemoved~BeeType,data=ex0327)
```


# 3(a) (2)

```{r}
ex0327$tPollenRemoved <- log(ex0327$PollenRemoved/(1-ex0327$PollenRemoved))
boxplot(tPollenRemoved~BeeType,data=ex0327)
```


# 3(a) (3)

```{r}
t.test(tPollenRemoved~BeeType,var.equal=TRUE,data = ex0327)
```


The calculated p-value is less than 0.05. So, at 5\% level of significance we can conclude that there is significant difference between Bee types in terms of Pollen removal proportion. 


# 3 (b) (1)

```{r}
boxplot(DurationOfVisit~BeeType,data=ex0327)

```

From the side by side box plot of original Duration variable we observed that there is outlier present
for Queen bees. 

\newpage

# 3 (b) (2)

```{r}

boxplot(log(DurationOfVisit)~BeeType,data=ex0327)

```
Again we observed outliers for queen bees for log transformed duration but the distribution looks symmetric for this transformation.  


\newpage
# 3 (b) (3)

```{r}

boxplot(1/DurationOfVisit~BeeType,data=ex0327)

```

Outlier present for both type of bee types when we consider reciprocal of the variable. 

# 3 (b) (4)

Among these three transformation, log transformation looks appropriate for t-tools or performing t-test because median are nearer to the center than other transformation. 

# 3 (b) (5)

```{r}
t.test(log(DurationOfVisit)~BeeType,var.equal=TRUE,data = ex0327)
```

The 95\% confidence interval is $(-1.118,-0.184)$.


# 3 (b) (6)

What are relative advantages of the three scales as far as interpretation goes? 

In applying different parametric statistical tests like t-test, we need the normality assumption to fulfill. Different scales helps to check whether the transformed data presenting the required shape or distribution to carry out the tests as far as interpretation goes. 


# 3 (b) (7)

Based on your experience with this problem, comment on the difficulty in assessing equality of population standard deviations from small samples.

```{r}
aggregate(PollenRemoved ~ BeeType, data = ex0327, length)
```

```{r}
aggregate(PollenRemoved ~ BeeType, data = ex0327, sd)
```

```{r}
aggregate(tPollenRemoved ~ BeeType, data = ex0327, sd)
```



```{r}
aggregate(DurationOfVisit ~ BeeType, data = ex0327, sd)
```

```{r}
aggregate(log(DurationOfVisit)~ BeeType, data = ex0327, sd)
```

From the analysis I observed that the population standard deviation is fluctuating too much as we are changing the scale of measurement in this data set. The reason might be the small sample in groups. 
